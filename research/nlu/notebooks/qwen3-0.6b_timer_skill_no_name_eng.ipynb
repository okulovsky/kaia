{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa408c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ed260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "your_token = input()\n",
    "login(token=your_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "182f1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d738a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"json\", data_files={\"train\": \"datalines/train.jsonl\", \"validation\": \"datalines/val.jsonl\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08cb3a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e37d7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(sample):\n",
    "    user = sample[\"USER\"]\n",
    "    hours = sample[\"HOURS\"]\n",
    "    minutes = sample[\"MINUTES\"]\n",
    "    seconds = sample[\"SECONDS\"]\n",
    "    return f\"USER¶{user}¶HOURS¶{hours}¶MINUTES¶{minutes}¶SECONDS¶{seconds}\" + tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56157e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f049290167749868c762750ef6c910c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692c17b07b514532905b748ae21bbd6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/669 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].map(lambda x: {\"text\": format_prompt(x)})\n",
    "dataset[\"validation\"] = dataset[\"validation\"].map(lambda x: {\"text\": format_prompt(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bfe932a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer(sample[\"text\"])[\"input_ids\"]) for sample in dataset[\"train\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75553b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer(sample[\"text\"])[\"input_ids\"]) for sample in dataset[\"validation\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a99a72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb3c930a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c71bcb8487542299c6b931014e2effd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc780ab7efb9407c85a171596db7f31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/669 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(sample):\n",
    "    prompt = f\"USER¶{sample['USER']}¶\"\n",
    "    prompt_len = len(tokenizer(prompt)[\"input_ids\"])\n",
    "    tokenized = tokenizer(\n",
    "        sample[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        max_length=42,\n",
    "        truncation=True,\n",
    "    )\n",
    "    pad_len = tokenized[\"input_ids\"].count(tokenizer.pad_token_id)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    tokenized[\"labels\"][:prompt_len] = [-100] * prompt_len\n",
    "    if pad_len > 0:\n",
    "        tokenized[\"labels\"][-pad_len:] = [-100] * pad_len\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].map(tokenize, batched=False)\n",
    "dataset[\"validation\"] = dataset[\"validation\"].map(tokenize, batched=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93215b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[6448, 54509, 40, 1184, 264, 9021, 369, 2326, 4115, 54509, 39, 59273, 54509, 18, 54509, 16413, 53785, 54509, 15, 54509, 925, 26904, 54509, 15, 151645, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 39, 59273, 54509, 18, 54509, 16413, 53785, 54509, 15, 54509, 925, 26904, 54509, 15, 151645, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0][\"attention_mask\"])\n",
    "print(dataset[\"train\"][0][\"input_ids\"])\n",
    "print(dataset[\"train\"][0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3a44265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151643"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb50704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    use_cache=False,\n",
    "    attn_implementation=\"eager\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f130e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.0,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "204c40fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33mWARN\u001b[0m  Python GIL is enabled: Multi-gpu quant acceleration for MoE models is sub-optimal and multi-core accelerated cpu packing is also disabled. We recommend Python >= 3.13.3t with Pytorch > 2.8 for mult-gpu quantization and multi-cpu packing with env `PYTHON_GIL=0`.\n",
      "\u001b[33mWARN\u001b[0m  Feature `utils/Perplexity` requires python GIL or Python >= 3.13.3T (T for Threading-Free edition of Python) plus Torch 2.8. Feature is currently skipped/disabled.\n",
      "\u001b[32mINFO\u001b[0m  ENV: Auto setting PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True' for memory saving.\n",
      "\u001b[32mINFO\u001b[0m  ENV: Auto setting CUDA_DEVICE_ORDER=PCI_BUS_ID for correctness.          \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5a3470d4b44569bf691b5a113626b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/2678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c267f234aede462491815053e08f5c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/669 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:cc -pthread -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall -fPIC -fPIC -c /tmp/tmp74vex3e2/test.c -o /tmp/tmp74vex3e2/test.o\n",
      "INFO:root:cc -pthread /tmp/tmp74vex3e2/test.o -laio -o /tmp/tmp74vex3e2/a.out\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "INFO:root:cc -pthread -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall -fPIC -fPIC -c /tmp/tmpz_nyb9r8/test.c -o /tmp/tmpz_nyb9r8/test.o\n",
      "INFO:root:cc -pthread /tmp/tmpz_nyb9r8/test.o -L/usr/local/cuda-12.6 -L/usr/local/cuda-12.6/lib64 -lcufile -o /tmp/tmpz_nyb9r8/a.out\n",
      "INFO:root:cc -pthread -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall -fPIC -fPIC -c /tmp/tmpghvxfuf7/test.c -o /tmp/tmpghvxfuf7/test.o\n",
      "INFO:root:cc -pthread /tmp/tmpghvxfuf7/test.o -laio -o /tmp/tmpghvxfuf7/a.out\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 02:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.010720</td>\n",
       "      <td>1.971098</td>\n",
       "      <td>33600.000000</td>\n",
       "      <td>0.996940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>1.881108</td>\n",
       "      <td>67200.000000</td>\n",
       "      <td>0.998031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>2.026359</td>\n",
       "      <td>100800.000000</td>\n",
       "      <td>0.999292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>1.999228</td>\n",
       "      <td>133980.000000</td>\n",
       "      <td>0.999386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>2.057052</td>\n",
       "      <td>167580.000000</td>\n",
       "      <td>0.998768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>1.997125</td>\n",
       "      <td>201180.000000</td>\n",
       "      <td>0.999198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>1.967222</td>\n",
       "      <td>234360.000000</td>\n",
       "      <td>0.999289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>1.957014</td>\n",
       "      <td>267960.000000</td>\n",
       "      <td>0.999289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>1.956357</td>\n",
       "      <td>301560.000000</td>\n",
       "      <td>0.999289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>1.957504</td>\n",
       "      <td>335160.000000</td>\n",
       "      <td>0.999289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=252, training_loss=0.09902305537211543, metrics={'train_runtime': 180.0699, 'train_samples_per_second': 44.616, 'train_steps_per_second': 1.399, 'total_flos': 912189358080000.0, 'train_loss': 0.09902305537211543, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen-timer-lora\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=25,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=25,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=[],\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    seed=887,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    peft_config=peft_config,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64bbb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./qwen-timer-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d7f4859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "sample_template = \"HOURS¶{}¶MINUTES¶{}¶SECONDS¶{}\" + tokenizer.eos_token\n",
    "\n",
    "max_new_tokens = max(\n",
    "    [\n",
    "        len(tokenizer.tokenize(sample_template.format(h, m, s)))\n",
    "        for h, m, s in product(range(100), repeat=3)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3be9f7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c18c15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "840cd306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f81ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"cuda\")\n",
    "model = PeftModel.from_pretrained(base_model, \"./qwen-timer-lora\", device_map=\"cuda\")\n",
    "text_gen = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74656abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def evaluate_accuracy(\n",
    "    dataset,\n",
    "    log_file,\n",
    "    batch_size=64,\n",
    "):\n",
    "    correct = 0\n",
    "    total = len(dataset)\n",
    "\n",
    "    with open(log_file, \"w\") as file:\n",
    "        for i in tqdm(range(0, total, batch_size)):\n",
    "            texts = [\n",
    "                text.replace(tokenizer.eos_token, \"\")\n",
    "                for text in dataset[i : i + batch_size][\"text\"]\n",
    "            ]\n",
    "            prefixes = [\"¶\".join(text.split(\"¶\")[:2]) + \"¶\" for text in texts]\n",
    "            print(prefixes[0])\n",
    "            gen_outs = text_gen(\n",
    "                prefixes,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                num_beams=1,\n",
    "                do_sample=False,\n",
    "                batch_size=batch_size,\n",
    "            )\n",
    "            for text, gen_out in zip(texts, gen_outs):\n",
    "                gen_text = gen_out[0][\"generated_text\"]\n",
    "                if len(gen_text) >= len(text) and text == gen_text[: len(text)]:\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    print(f\"Mismatch: {text} -> {gen_text}\\n\", file=file)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d52a83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                      | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER¶I need you to start a timer for 16 hours.¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████████▉                                                                                                                                 | 1/11 [00:01<00:12,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER¶please start a timer for 4 minutes¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████████████▊                                                                                                                    | 2/11 [00:02<00:11,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER¶Please set a half hour timer¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████████████████████▋                                                                                                       | 3/11 [00:03<00:09,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER¶please start a timer for 1 hour and 20 minutes¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████████████████████████▋                                                                                          | 4/11 [00:04<00:08,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER¶Hey set a timer for three hours¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████████████████████████████████████▌                                                                             | 5/11 [00:06<00:07,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER¶start a timer for seven hours, thirty-four minutes and eighteen seconds¶\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m acc = \u001b[43mevaluate_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalidation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval.log\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValidation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mevaluate_accuracy\u001b[39m\u001b[34m(dataset, log_file, batch_size)\u001b[39m\n\u001b[32m     18\u001b[39m prefixes = [\u001b[33m\"\u001b[39m\u001b[33m¶\u001b[39m\u001b[33m\"\u001b[39m.join(text.split(\u001b[33m\"\u001b[39m\u001b[33m¶\u001b[39m\u001b[33m\"\u001b[39m)[:\u001b[32m2\u001b[39m]) + \u001b[33m\"\u001b[39m\u001b[33m¶\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(prefixes[\u001b[32m0\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m gen_outs = \u001b[43mtext_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text, gen_out \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(texts, gen_outs):\n\u001b[32m     28\u001b[39m     gen_text = gen_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:332\u001b[39m, in \u001b[36mTextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, text_inputs, **kwargs)\u001b[39m\n\u001b[32m    330\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1448\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[32m   1445\u001b[39m     final_iterator = \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   1446\u001b[39m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[32m   1447\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:126\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:127\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m    126\u001b[39m item = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator)\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    130\u001b[39m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1374\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1372\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1373\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:432\u001b[39m, in \u001b[36mTextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    430\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[32m    435\u001b[39m     generated_sequence = output.sequences\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/peft/peft_model.py:1973\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1971\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1972\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1973\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1974\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1975\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2539\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GenerationMixin.generate(\n\u001b[32m   2529\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2530\u001b[39m         inputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2534\u001b[39m         **kwargs,\n\u001b[32m   2535\u001b[39m     )\n\u001b[32m   2537\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.SAMPLE, GenerationMode.GREEDY_SEARCH):\n\u001b[32m   2538\u001b[39m     \u001b[38;5;66;03m# 11. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2539\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2544\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2546\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2547\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2550\u001b[39m     \u001b[38;5;66;03m# 11. run beam sample\u001b[39;00m\n\u001b[32m   2551\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._beam_search(\n\u001b[32m   2552\u001b[39m         input_ids,\n\u001b[32m   2553\u001b[39m         logits_processor=prepared_logits_processor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2557\u001b[39m         **model_kwargs,\n\u001b[32m   2558\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2867\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2864\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   2866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m2867\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2868\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2869\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:940\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    939\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m940\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    942\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:480\u001b[39m, in \u001b[36mQwen3ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    444\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    456\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    457\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    458\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[33;03m    labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[33;03m        Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    478\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    492\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 module.forward = make_capture_wrapper(module, original_forward, key, specs.index)\n\u001b[32m   1062\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;66;03m# Restore original forward methods\u001b[39;00m\n\u001b[32m   1066\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module, original_forward \u001b[38;5;129;01min\u001b[39;00m monkey_patched_layers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:410\u001b[39m, in \u001b[36mQwen3Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    407\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    423\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    424\u001b[39m     past_key_values=past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    425\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:275\u001b[39m, in \u001b[36mQwen3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    273\u001b[39m residual = hidden_states\n\u001b[32m    274\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:82\u001b[39m, in \u001b[36mQwen3MLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     down_proj = \u001b[38;5;28mself\u001b[39m.down_proj(\u001b[38;5;28mself\u001b[39m.act_fn(\u001b[38;5;28mself\u001b[39m.gate_proj(x)) * \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaia_exps/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1769\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1766\u001b[39m             tracing_state.pop_scope()\n\u001b[32m   1767\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m1769\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1770\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1771\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "acc = evaluate_accuracy(dataset[\"validation\"], log_file=\"eval.log\")\n",
    "print(f\"Validation accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1488bad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER¶I need you to start a timer for 16 hours.¶HOURS¶16¶MINUTES¶0¶SECONDS¶0<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"validation\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01e6d607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch: USER¶I need you to start a timer for 16 hours.¶HOURS¶16¶MINUTES¶0¶SECONDS¶0 -> USER¶I need you to start a timer for 16 hours.¶\n",
      "\n",
      "Mismatch: USER¶i want a 3 hour, 15 minute timer¶HOURS¶3¶MINUTES¶15¶SECONDS¶0 -> USER¶i want a 3 hour, 15 minute timer¶¶HOURS¶3¶MINUTES¶15¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start a 1 hour 59 minute timer¶HOURS¶1¶MINUTES¶59¶SECONDS¶0 -> USER¶start a 1 hour 59 minute timer¶\n",
      "\n",
      "Mismatch: USER¶Start a timer for forty four hours¶HOURS¶44¶MINUTES¶0¶SECONDS¶0 -> USER¶Start a timer for forty four hours¶\n",
      "\n",
      "Mismatch: USER¶Start a timer for 90 minutes.¶HOURS¶0¶MINUTES¶90¶SECONDS¶0 -> USER¶Start a timer for 90 minutes.¶90\n",
      "\n",
      "Mismatch: USER¶one and three quarter hour timer with 13 seconds, start¶HOURS¶1¶MINUTES¶45¶SECONDS¶13 -> USER¶one and three quarter hour timer with 13 seconds, start¶¶HOURS¶1¶MINUTES¶15¶SECONDS¶13\n",
      "\n",
      "Mismatch: USER¶start timer for three hours and twenty seven minutes¶HOURS¶3¶MINUTES¶27¶SECONDS¶0 -> USER¶start timer for three hours and twenty seven minutes¶\n",
      "\n",
      "Mismatch: USER¶start a timer for 9 minutes¶HOURS¶0¶MINUTES¶9¶SECONDS¶0 -> USER¶start a timer for 9 minutes¶9HOURS¶0¶MINUTES¶9¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Start a countdown for two hours and two minutes¶HOURS¶2¶MINUTES¶2¶SECONDS¶0 -> USER¶Start a countdown for two hours and two minutes¶¶HOURS¶2¶MINUTES¶2¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Create a timer for seventy two seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶72 -> USER¶Create a timer for seventy two seconds¶\n",
      "\n",
      "Mismatch: USER¶I need you to time 1 hour for me.¶HOURS¶1¶MINUTES¶0¶SECONDS¶0 -> USER¶I need you to time 1 hour for me.¶¶HOURS¶1¶MINUTES¶0¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start a timer for 2 hours and 2 seconds¶HOURS¶2¶MINUTES¶0¶SECONDS¶2 -> USER¶start a timer for 2 hours and 2 seconds¶\n",
      "\n",
      "Mismatch: USER¶I'd like to have a timer for eight hours and thirty minutes¶HOURS¶8¶MINUTES¶30¶SECONDS¶0 -> USER¶I'd like to have a timer for eight hours and thirty minutes¶¶HOURS¶8¶MINUTES¶30¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Give me a timer lasting 8 hours 8 minutes¶HOURS¶8¶MINUTES¶8¶SECONDS¶0 -> USER¶Give me a timer lasting 8 hours 8 minutes¶8HOURS¶8¶MINUTES¶8¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Start a timer for twenty-two minutes.¶HOURS¶0¶MINUTES¶22¶SECONDS¶0 -> USER¶Start a timer for twenty-two minutes.¶2HOURS¶0¶MINUTES¶22¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶i want a 5 hour 5 minute countdown¶HOURS¶5¶MINUTES¶5¶SECONDS¶0 -> USER¶i want a 5 hour 5 minute countdown¶5HOURS¶5¶MINUTES¶5¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶I want a timer for 36 minutes 12 seconds¶HOURS¶0¶MINUTES¶36¶SECONDS¶12 -> USER¶I want a timer for 36 minutes 12 seconds¶¶HOURS¶0¶MINUTES¶36¶SECONDS¶12\n",
      "\n",
      "Mismatch: USER¶set me a timer for 59 seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶59 -> USER¶set me a timer for 59 seconds¶\n",
      "\n",
      "Mismatch: USER¶launch a timer for 8 minutes and 20 seconds¶HOURS¶0¶MINUTES¶8¶SECONDS¶20 -> USER¶launch a timer for 8 minutes and 20 seconds¶8HOURS¶0¶MINUTES¶8¶SECONDS¶20\n",
      "\n",
      "Mismatch: USER¶Start a ninety five second timer¶HOURS¶0¶MINUTES¶0¶SECONDS¶95 -> USER¶Start a ninety five second timer¶\n",
      "\n",
      "Mismatch: USER¶create a timer for twenty two minutes and one second¶HOURS¶0¶MINUTES¶22¶SECONDS¶1 -> USER¶create a timer for twenty two minutes and one second¶22¶1¶HOURS¶0¶MINUTES¶22¶SECONDS\n",
      "\n",
      "Mismatch: USER¶kick off a 20 seconds followed by 1 hour 45 minutes¶HOURS¶1¶MINUTES¶45¶SECONDS¶20 -> USER¶kick off a 20 seconds followed by 1 hour 45 minutes¶¶HOURS¶1¶MINUTES¶45¶SECONDS¶20\n",
      "\n",
      "Mismatch: USER¶Please start a timer for 61 minutes.¶HOURS¶0¶MINUTES¶61¶SECONDS¶0 -> USER¶Please start a timer for 61 minutes.¶6HOURS¶0¶MINUTES¶61¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Please set a timer for ninety nine minutes¶HOURS¶0¶MINUTES¶99¶SECONDS¶0 -> USER¶Please set a timer for ninety nine minutes¶¶HOURS¶0¶MINUTES¶99¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶quarter hour and 13 seconds, let's start¶HOURS¶0¶MINUTES¶15¶SECONDS¶13 -> USER¶quarter hour and 13 seconds, let's start¶¶HOURS¶0¶MINUTES¶15¶SECONDS¶13\n",
      "\n",
      "Mismatch: USER¶launch a timer for 2 hours, 35 minutes and 15 seconds¶HOURS¶2¶MINUTES¶35¶SECONDS¶15 -> USER¶launch a timer for 2 hours, 35 minutes and 15 seconds¶\n",
      "\n",
      "Mismatch: USER¶hey assistant, set timer for 6 hours 50 minutes¶HOURS¶6¶MINUTES¶50¶SECONDS¶0 -> USER¶hey assistant, set timer for 6 hours 50 minutes¶¶HOURS¶6¶MINUTES¶50¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶launch a 6 hour timer¶HOURS¶6¶MINUTES¶0¶SECONDS¶0 -> USER¶launch a 6 hour timer¶\n",
      "\n",
      "Mismatch: USER¶start a timer for 13 hours¶HOURS¶13¶MINUTES¶0¶SECONDS¶0 -> USER¶start a timer for 13 hours¶1HOURS¶13¶MINUTES¶0¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start a timer for seventy-eight seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶78 -> USER¶start a timer for seventy-eight seconds¶78\n",
      "\n",
      "Mismatch: USER¶activate a timer for 25 seconds followed by three quarter hour¶HOURS¶0¶MINUTES¶45¶SECONDS¶25 -> USER¶activate a timer for 25 seconds followed by three quarter hour¶\n",
      "\n",
      "Mismatch: USER¶Please set a countdown for eighty five seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶85 -> USER¶Please set a countdown for eighty five seconds¶¶HOURS¶0¶MINUTES¶0¶SECONDS¶85\n",
      "\n",
      "Mismatch: USER¶begin a nine hour and twenty-two minute countdown¶HOURS¶9¶MINUTES¶22¶SECONDS¶0 -> USER¶begin a nine hour and twenty-two minute countdown¶9HOURS¶9¶MINUTES¶22¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶kick off a 25 seconds followed by 1 hour 45 minutes¶HOURS¶1¶MINUTES¶45¶SECONDS¶25 -> USER¶kick off a 25 seconds followed by 1 hour 45 minutes¶¶HOURS¶1¶MINUTES¶45¶SECONDS¶25\n",
      "\n",
      "Mismatch: USER¶Timer for sixteen hours and four minutes please¶HOURS¶16¶MINUTES¶4¶SECONDS¶0 -> USER¶Timer for sixteen hours and four minutes please¶¶HOURS¶16¶MINUTES¶4¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Timer, please! For 20 minutes.¶HOURS¶0¶MINUTES¶20¶SECONDS¶0 -> USER¶Timer, please! For 20 minutes.¶2HOURS¶0¶MINUTES¶20¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Start a timer for ninety nine hours¶HOURS¶99¶MINUTES¶0¶SECONDS¶0 -> USER¶Start a timer for ninety nine hours¶\n",
      "\n",
      "Mismatch: USER¶start a timer for 77 hours¶HOURS¶77¶MINUTES¶0¶SECONDS¶0 -> USER¶start a timer for 77 hours¶77¶HOURS¶77¶MINUTES¶0¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Start a 3-second timer.¶HOURS¶0¶MINUTES¶0¶SECONDS¶3 -> USER¶Start a 3-second timer.¶\n",
      "\n",
      "Mismatch: USER¶quarter hour plus 21 seconds, start¶HOURS¶0¶MINUTES¶15¶SECONDS¶21 -> USER¶quarter hour plus 21 seconds, start¶¶HOURS¶0¶MINUTES¶15¶SECONDS¶21\n",
      "\n",
      "Mismatch: USER¶Start a forty nine minute and twenty one second timer¶HOURS¶0¶MINUTES¶49¶SECONDS¶21 -> USER¶Start a forty nine minute and twenty one second timer¶49¶21¶0\n",
      "\n",
      "Mismatch: USER¶please create a timer for 2 hours and 25 minutes¶HOURS¶2¶MINUTES¶25¶SECONDS¶0 -> USER¶please create a timer for 2 hours and 25 minutes¶\n",
      "\n",
      "Mismatch: USER¶start a timer for one hour and five seconds¶HOURS¶1¶MINUTES¶0¶SECONDS¶5 -> USER¶start a timer for one hour and five seconds¶\n",
      "\n",
      "Mismatch: USER¶please start a three quarter hour and 35 second timer¶HOURS¶0¶MINUTES¶45¶SECONDS¶35 -> USER¶please start a three quarter hour and 35 second timer¶\n",
      "\n",
      "Mismatch: USER¶Start a timer that lasts 15 hours¶HOURS¶15¶MINUTES¶0¶SECONDS¶0 -> USER¶Start a timer that lasts 15 hours¶\n",
      "\n",
      "Mismatch: USER¶start a timer for 8 minutes and 20 seconds¶HOURS¶0¶MINUTES¶8¶SECONDS¶20 -> USER¶start a timer for 8 minutes and 20 seconds¶8HOURS¶0¶MINUTES¶8¶SECONDS¶20\n",
      "\n",
      "Mismatch: USER¶please put a timer for ninety nine hours, ninety nine minutes and ninety nine seconds¶HOURS¶99¶MINUTES¶99¶SECONDS¶99 -> USER¶please put a timer for ninety nine hours, ninety nine minutes and ninety nine seconds¶\n",
      "\n",
      "Mismatch: USER¶Start a timer for nineteen minutes and four seconds¶HOURS¶0¶MINUTES¶19¶SECONDS¶4 -> USER¶Start a timer for nineteen minutes and four seconds¶\n",
      "\n",
      "Mismatch: USER¶begin a countdown of 12 seconds plus three quarter hour¶HOURS¶0¶MINUTES¶45¶SECONDS¶12 -> USER¶begin a countdown of 12 seconds plus three quarter hour¶\n",
      "\n",
      "Mismatch: USER¶I need a timer for 5 hours and 45 minutes.¶HOURS¶5¶MINUTES¶45¶SECONDS¶0 -> USER¶I need a timer for 5 hours and 45 minutes.¶\n",
      "\n",
      "Mismatch: USER¶please start a timer for 1 hour and 20 minutes¶HOURS¶1¶MINUTES¶20¶SECONDS¶0 -> USER¶please start a timer for 1 hour and 20 minutes¶\n",
      "\n",
      "Mismatch: USER¶launch a one hour and forty-five minute timer¶HOURS¶1¶MINUTES¶45¶SECONDS¶0 -> USER¶launch a one hour and forty-five minute timer¶1HOURS¶1¶MINUTES¶45¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶i need a timer for 3 hours and 75 minutes¶HOURS¶3¶MINUTES¶75¶SECONDS¶0 -> USER¶i need a timer for 3 hours and 75 minutes¶¶HOURS¶3¶MINUTES¶75¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Please initiate a timer for 1 hour and a quarter.¶HOURS¶1¶MINUTES¶15¶SECONDS¶0 -> USER¶Please initiate a timer for 1 hour and a quarter.¶\n",
      "\n",
      "Mismatch: USER¶start a timer for 44 minutes¶HOURS¶0¶MINUTES¶44¶SECONDS¶0 -> USER¶start a timer for 44 minutes¶4HOURS¶0¶MINUTES¶44¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Can you please start a timer for 2 and a half minutes?¶HOURS¶0¶MINUTES¶2¶SECONDS¶30 -> USER¶Can you please start a timer for 2 and a half minutes?¶\n",
      "\n",
      "Mismatch: USER¶Hey, set a timer for a minute and a half.¶HOURS¶0¶MINUTES¶1¶SECONDS¶30 -> USER¶Hey, set a timer for a minute and a half.¶¶HOURS¶0¶MINUTES¶30¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶please start a timer for 9 minutes and 59 seconds¶HOURS¶0¶MINUTES¶9¶SECONDS¶59 -> USER¶please start a timer for 9 minutes and 59 seconds¶9HOURS¶0¶MINUTES¶9¶SECONDS¶59\n",
      "\n",
      "Mismatch: USER¶put a timer on for 4 minutes and 30 seconds¶HOURS¶0¶MINUTES¶4¶SECONDS¶30 -> USER¶put a timer on for 4 minutes and 30 seconds¶4HOURS¶0¶MINUTES¶4¶SECONDS¶30\n",
      "\n",
      "Mismatch: USER¶Start 16 hours and 30 minutes timer¶HOURS¶16¶MINUTES¶30¶SECONDS¶0 -> USER¶Start 16 hours and 30 minutes timer¶¶HOURS¶16¶MINUTES¶30¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶I need a quick ten second timer¶HOURS¶0¶MINUTES¶0¶SECONDS¶10 -> USER¶I need a quick ten second timer¶\n",
      "\n",
      "Mismatch: USER¶one and a half hours with 40 seconds, start¶HOURS¶1¶MINUTES¶30¶SECONDS¶40 -> USER¶one and a half hours with 40 seconds, start¶¶HOURS¶1¶MINUTES¶30¶SECONDS¶40\n",
      "\n",
      "Mismatch: USER¶Start a timer for seven hours and forty eight minutes¶HOURS¶7¶MINUTES¶48¶SECONDS¶0 -> USER¶Start a timer for seven hours and forty eight minutes¶\n",
      "\n",
      "Mismatch: USER¶one and three quarter hour timer with 18 seconds, go¶HOURS¶1¶MINUTES¶45¶SECONDS¶18 -> USER¶one and three quarter hour timer with 18 seconds, go¶¶HOURS¶1¶MINUTES¶45¶SECONDS¶18\n",
      "\n",
      "Mismatch: USER¶Please make a timer for fifty three minutes¶HOURS¶0¶MINUTES¶53¶SECONDS¶0 -> USER¶Please make a timer for fifty three minutes¶\n",
      "\n",
      "Mismatch: USER¶start a timer for twenty-one seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶21 -> USER¶start a timer for twenty-one seconds¶2HOURS¶0¶MINUTES¶0¶SECONDS¶21\n",
      "\n",
      "Mismatch: USER¶Please set a timer for one hour¶HOURS¶1¶MINUTES¶0¶SECONDS¶0 -> USER¶Please set a timer for one hour¶¶HOURS¶1¶¶MINUTES¶0¶¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶please launch a timer for 2 hours and 15 minutes¶HOURS¶2¶MINUTES¶15¶SECONDS¶0 -> USER¶please launch a timer for 2 hours and 15 minutes¶\n",
      "\n",
      "Mismatch: USER¶start a timer for 25 hours and 5 minutes¶HOURS¶25¶MINUTES¶5¶SECONDS¶0 -> USER¶start a timer for 25 hours and 5 minutes¶\n",
      "\n",
      "Mismatch: USER¶start a 40 hour timer¶HOURS¶40¶MINUTES¶0¶SECONDS¶0 -> USER¶start a 40 hour timer¶\n",
      "\n",
      "Mismatch: USER¶start a timer for half a minute and 15 seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶45 -> USER¶start a timer for half a minute and 15 seconds¶\n",
      "\n",
      "Mismatch: USER¶start a timer for 25 seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶25 -> USER¶start a timer for 25 seconds¶2HOURS¶0¶MINUTES¶0¶SECONDS¶25\n",
      "\n",
      "Mismatch: USER¶Timer for nine minutes and fifty nine seconds please¶HOURS¶0¶MINUTES¶9¶SECONDS¶59 -> USER¶Timer for nine minutes and fifty nine seconds please¶¶HOURS¶0¶MINUTES¶9¶SECONDS¶59\n",
      "\n",
      "Mismatch: USER¶start a timer for quarter of an hour¶HOURS¶0¶MINUTES¶15¶SECONDS¶0 -> USER¶start a timer for quarter of an hour¶\n",
      "\n",
      "Mismatch: USER¶Start a timer for five minutes and twenty seconds¶HOURS¶0¶MINUTES¶5¶SECONDS¶20 -> USER¶Start a timer for five minutes and twenty seconds¶\n",
      "\n",
      "Mismatch: USER¶start a 5 second timer now¶HOURS¶0¶MINUTES¶0¶SECONDS¶5 -> USER¶start a 5 second timer now¶\n",
      "\n",
      "Mismatch: USER¶i want a countdown for 90 minutes¶HOURS¶0¶MINUTES¶90¶SECONDS¶0 -> USER¶i want a countdown for 90 minutes¶¶HOURS¶0¶MINUTES¶90¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Please initiate a timer for fifty seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶50 -> USER¶Please initiate a timer for fifty seconds¶\n",
      "\n",
      "Mismatch: USER¶create a timer for five minutes and seven seconds¶HOURS¶0¶MINUTES¶5¶SECONDS¶7 -> USER¶create a timer for five minutes and seven seconds¶\n",
      "\n",
      "Mismatch: USER¶I want you to set a timer for seven minutes¶HOURS¶0¶MINUTES¶7¶SECONDS¶0 -> USER¶I want you to set a timer for seven minutes¶¶HOURS¶0¶MINUTES¶7¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶please start a 3 hour and 10 minute timer¶HOURS¶3¶MINUTES¶10¶SECONDS¶0 -> USER¶please start a 3 hour and 10 minute timer¶3HOURS¶3¶MINUTES¶10¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start me a timer for 29 minutes¶HOURS¶0¶MINUTES¶29¶SECONDS¶0 -> USER¶start me a timer for 29 minutes¶\n",
      "\n",
      "Mismatch: USER¶start a 15 minute and 9 second timer¶HOURS¶0¶MINUTES¶15¶SECONDS¶9 -> USER¶start a 15 minute and 9 second timer¶\n",
      "\n",
      "Mismatch: USER¶Timer for one and a half hours please¶HOURS¶1¶MINUTES¶30¶SECONDS¶0 -> USER¶Timer for one and a half hours please¶¶HOURS¶1¶MINUTES¶30¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start a 9 hour and 15 minute timer¶HOURS¶9¶MINUTES¶15¶SECONDS¶0 -> USER¶start a 9 hour and 15 minute timer¶¶HOURS¶9¶MINUTES¶15¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start timer for one hour thirty five minutes and forty seconds¶HOURS¶1¶MINUTES¶35¶SECONDS¶40 -> USER¶start timer for one hour thirty five minutes and forty seconds¶1HOURS¶1¶MINUTES¶35¶SECONDS¶40\n",
      "\n",
      "Mismatch: USER¶I want a timer for eight minutes and twenty four seconds¶HOURS¶0¶MINUTES¶8¶SECONDS¶24 -> USER¶I want a timer for eight minutes and twenty four seconds¶¶HOURS¶0¶MINUTES¶8¶SECONDS¶24\n",
      "\n",
      "Mismatch: USER¶please start a timer for 55 minutes and 15 seconds¶HOURS¶0¶MINUTES¶55¶SECONDS¶15 -> USER¶please start a timer for 55 minutes and 15 seconds¶\n",
      "\n",
      "Mismatch: USER¶Start a timer for fourteen minutes and eleven seconds¶HOURS¶0¶MINUTES¶14¶SECONDS¶11 -> USER¶Start a timer for fourteen minutes and eleven seconds¶\n",
      "\n",
      "Mismatch: USER¶start a timer for eight hours and ten minutes¶HOURS¶8¶MINUTES¶10¶SECONDS¶0 -> USER¶start a timer for eight hours and ten minutes¶\n",
      "\n",
      "Mismatch: USER¶timer for thirteen hours and thirty seven minutes please¶HOURS¶13¶MINUTES¶37¶SECONDS¶0 -> USER¶timer for thirteen hours and thirty seven minutes please¶¶HOURS¶13¶MINUTES¶37¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶please set a timer for 90 seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶90 -> USER¶please set a timer for 90 seconds¶\n",
      "\n",
      "Mismatch: USER¶start a three quarters hour plus 18 seconds countdown¶HOURS¶0¶MINUTES¶45¶SECONDS¶18 -> USER¶start a three quarters hour plus 18 seconds countdown¶¶HOURS¶0¶MINUTES¶45¶SECONDS¶18\n",
      "\n",
      "Mismatch: USER¶i want a timer for forty-seven minutes¶HOURS¶0¶MINUTES¶47¶SECONDS¶0 -> USER¶i want a timer for forty-seven minutes¶¶HOURS¶0¶MINUTES¶47¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start a one hour timer¶HOURS¶1¶MINUTES¶0¶SECONDS¶0 -> USER¶start a one hour timer¶\n",
      "\n",
      "Mismatch: USER¶Start a timer for 3 hours and 33 minutes.¶HOURS¶3¶MINUTES¶33¶SECONDS¶0 -> USER¶Start a timer for 3 hours and 33 minutes.¶\n",
      "\n",
      "Mismatch: USER¶Timer for 1 minute, please.¶HOURS¶0¶MINUTES¶1¶SECONDS¶0 -> USER¶Timer for 1 minute, please.¶1HOURS¶0¶MINUTES¶1¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Start a seventy seven minute timer¶HOURS¶0¶MINUTES¶77¶SECONDS¶0 -> USER¶Start a seventy seven minute timer¶\n",
      "\n",
      "Mismatch: USER¶start a nine minute and forty-eight second timer¶HOURS¶0¶MINUTES¶9¶SECONDS¶48 -> USER¶start a nine minute and forty-eight second timer¶9¶48\n",
      "\n",
      "Mismatch: USER¶start a timer for 90 seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶90 -> USER¶start a timer for 90 seconds¶90\n",
      "\n",
      "Mismatch: USER¶Please set a timer for 2 hours and 5 minutes.¶HOURS¶2¶MINUTES¶5¶SECONDS¶0 -> USER¶Please set a timer for 2 hours and 5 minutes.¶¶HOURS¶2¶MINUTES¶5¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶please start a twenty second timer¶HOURS¶0¶MINUTES¶0¶SECONDS¶20 -> USER¶please start a twenty second timer¶\n",
      "\n",
      "Mismatch: USER¶Start a timer for three hours and forty eight minutes¶HOURS¶3¶MINUTES¶48¶SECONDS¶0 -> USER¶Start a timer for three hours and forty eight minutes¶\n",
      "\n",
      "Mismatch: USER¶start a timer for four hours and thirty minutes¶HOURS¶4¶MINUTES¶30¶SECONDS¶0 -> USER¶start a timer for four hours and thirty minutes¶\n",
      "\n",
      "Mismatch: USER¶put a timer on for 99 minutes¶HOURS¶0¶MINUTES¶99¶SECONDS¶0 -> USER¶put a timer on for 99 minutes¶99\n",
      "\n",
      "Mismatch: USER¶i need a timer for three minutes¶HOURS¶0¶MINUTES¶3¶SECONDS¶0 -> USER¶i need a timer for three minutes¶\n",
      "\n",
      "Mismatch: USER¶please start a 2 hour 14 minute timer¶HOURS¶2¶MINUTES¶14¶SECONDS¶0 -> USER¶please start a 2 hour 14 minute timer¶\n",
      "\n",
      "Mismatch: USER¶Could you set a timer for twelve hours and four minutes¶HOURS¶12¶MINUTES¶4¶SECONDS¶0 -> USER¶Could you set a timer for twelve hours and four minutes¶¶HOURS¶12¶MINUTES¶4¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start a timer for 53 minutes¶HOURS¶0¶MINUTES¶53¶SECONDS¶0 -> USER¶start a timer for 53 minutes¶53¶HOURS¶0¶MINUTES¶53¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶I want a timer for 10 seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶10 -> USER¶I want a timer for 10 seconds¶\n",
      "\n",
      "Mismatch: USER¶Start a timer for 3 minutes.¶HOURS¶0¶MINUTES¶3¶SECONDS¶0 -> USER¶Start a timer for 3 minutes.¶3HOURS¶0¶MINUTES¶3¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Could you set a two hour timer for me¶HOURS¶2¶MINUTES¶0¶SECONDS¶0 -> USER¶Could you set a two hour timer for me¶¶HOURS¶2¶¶MINUTES¶0¶¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start a quarter of an hour timer¶HOURS¶0¶MINUTES¶15¶SECONDS¶0 -> USER¶start a quarter of an hour timer¶\n",
      "\n",
      "Mismatch: USER¶Start a timer for seventy minutes and three seconds¶HOURS¶0¶MINUTES¶70¶SECONDS¶3 -> USER¶Start a timer for seventy minutes and three seconds¶\n",
      "\n",
      "Mismatch: USER¶i want you to start a 3 hour timer¶HOURS¶3¶MINUTES¶0¶SECONDS¶0 -> USER¶i want you to start a 3 hour timer¶¶HOURS¶3¶¶MINUTES¶0¶¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶I want a timer for 2 minutes¶HOURS¶0¶MINUTES¶2¶SECONDS¶0 -> USER¶I want a timer for 2 minutes¶¶HOURS¶0¶MINUTES¶2¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Start a 99 minute timer now¶HOURS¶0¶MINUTES¶99¶SECONDS¶0 -> USER¶Start a 99 minute timer now¶\n",
      "\n",
      "Mismatch: USER¶launch a three hour and thirty-two minute countdown¶HOURS¶3¶MINUTES¶32¶SECONDS¶0 -> USER¶launch a three hour and thirty-two minute countdown¶3HOURS¶3¶MINUTES¶32¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶half a minute and 22 seconds, go¶HOURS¶0¶MINUTES¶0¶SECONDS¶52 -> USER¶half a minute and 22 seconds, go¶HOURS¶0¶MINUTES¶0¶SECONDS¶22\n",
      "\n",
      "Mismatch: USER¶start a timer for 48 seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶48 -> USER¶start a timer for 48 seconds¶4HOURS¶0¶MINUTES¶0¶SECONDS¶48\n",
      "\n",
      "Mismatch: USER¶Create a timer lasting 41 minutes¶HOURS¶0¶MINUTES¶41¶SECONDS¶0 -> USER¶Create a timer lasting 41 minutes¶41¶HOURS¶0¶MINUTES¶41¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start a 60 seconds and 2 hour timer¶HOURS¶2¶MINUTES¶0¶SECONDS¶60 -> USER¶start a 60 seconds and 2 hour timer¶¶HOURS¶2¶SECONDS¶60¶MINUTES¶0¶SE\n",
      "\n",
      "Mismatch: USER¶activate a 1 hour 50 second timer¶HOURS¶1¶MINUTES¶0¶SECONDS¶50 -> USER¶activate a 1 hour 50 second timer¶1HOURS¶1¶MINUTES¶0¶SECONDS¶50\n",
      "\n",
      "Mismatch: USER¶start a 4 hour, 5 minute and 10 second timer¶HOURS¶4¶MINUTES¶5¶SECONDS¶10 -> USER¶start a 4 hour, 5 minute and 10 second timer¶4HOURS¶4¶MINUTES¶5¶SECONDS¶10\n",
      "\n",
      "Mismatch: USER¶Could you set a timer for seventeen hours and nine minutes¶HOURS¶17¶MINUTES¶9¶SECONDS¶0 -> USER¶Could you set a timer for seventeen hours and nine minutes¶¶HOURS¶17¶MINUTES¶9¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶please start a 1 hour and 50 second timer¶HOURS¶1¶MINUTES¶0¶SECONDS¶50 -> USER¶please start a 1 hour and 50 second timer¶1HOURS¶1¶MINUTES¶0¶SECONDS¶50\n",
      "\n",
      "Mismatch: USER¶I want a timer for nine hours and five seconds¶HOURS¶9¶MINUTES¶0¶SECONDS¶5 -> USER¶I want a timer for nine hours and five seconds¶¶HOURS¶9¶MINUTES¶0¶SECONDS¶5\n",
      "\n",
      "Mismatch: USER¶start a 1 hour and 30 second timer¶HOURS¶1¶MINUTES¶0¶SECONDS¶30 -> USER¶start a 1 hour and 30 second timer¶\n",
      "\n",
      "Mismatch: USER¶start a timer for 33 minutes¶HOURS¶0¶MINUTES¶33¶SECONDS¶0 -> USER¶start a timer for 33 minutes¶3HOURS¶0¶MINUTES¶33¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start a countdown for 1 hour 7 minutes and 22 seconds¶HOURS¶1¶MINUTES¶7¶SECONDS¶22 -> USER¶start a countdown for 1 hour 7 minutes and 22 seconds¶1HOURS¶1¶MINUTES¶7¶SECONDS¶22\n",
      "\n",
      "Mismatch: USER¶Please start a timer for 6 hours.¶HOURS¶6¶MINUTES¶0¶SECONDS¶0 -> USER¶Please start a timer for 6 hours.¶\n",
      "\n",
      "Mismatch: USER¶kick off a three quarters hour with 33 seconds¶HOURS¶0¶MINUTES¶45¶SECONDS¶33 -> USER¶kick off a three quarters hour with 33 seconds¶¶HOURS¶0¶MINUTES¶45¶SECONDS¶33\n",
      "\n",
      "Mismatch: USER¶start a ten minute timer¶HOURS¶0¶MINUTES¶10¶SECONDS¶0 -> USER¶start a ten minute timer¶\n",
      "\n",
      "Mismatch: USER¶start a 2 hour 7 second timer¶HOURS¶2¶MINUTES¶0¶SECONDS¶7 -> USER¶start a 2 hour 7 second timer¶2HOURS¶2¶MINUTES¶0¶SECONDS¶7\n",
      "\n",
      "Mismatch: USER¶Start a countdown timer for 5 hours.¶HOURS¶5¶MINUTES¶0¶SECONDS¶0 -> USER¶Start a countdown timer for 5 hours.¶\n",
      "\n",
      "Mismatch: USER¶Start a timer of five minutes and thirty seconds¶HOURS¶0¶MINUTES¶5¶SECONDS¶30 -> USER¶Start a timer of five minutes and thirty seconds¶5¶30\n",
      "\n",
      "Mismatch: USER¶Please initiate a timer for 99 hours.¶HOURS¶99¶MINUTES¶0¶SECONDS¶0 -> USER¶Please initiate a timer for 99 hours.¶\n",
      "\n",
      "Mismatch: USER¶Hey, start a ninety nine minute countdown¶HOURS¶0¶MINUTES¶99¶SECONDS¶0 -> USER¶Hey, start a ninety nine minute countdown¶¶HOURS¶0¶MINUTES¶99¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start a timer for 18 minutes¶HOURS¶0¶MINUTES¶18¶SECONDS¶0 -> USER¶start a timer for 18 minutes¶1HOURS¶0¶MINUTES¶18¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶I need a timer for one hour and ten minutes¶HOURS¶1¶MINUTES¶10¶SECONDS¶0 -> USER¶I need a timer for one hour and ten minutes¶¶HOURS¶1¶MINUTES¶10¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶put a timer on for 25 minutes¶HOURS¶0¶MINUTES¶25¶SECONDS¶0 -> USER¶put a timer on for 25 minutes¶2HOURS¶0¶MINUTES¶25¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start a timer for thirty-nine seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶39 -> USER¶start a timer for thirty-nine seconds¶3HOURS¶0¶MINUTES¶0¶SECONDS¶39\n",
      "\n",
      "Mismatch: USER¶quarter hour plus 26 seconds, please begin¶HOURS¶0¶MINUTES¶15¶SECONDS¶26 -> USER¶quarter hour plus 26 seconds, please begin¶¶HOURS¶0¶MINUTES¶15¶SECONDS¶26\n",
      "\n",
      "Mismatch: USER¶start a timer for 8 hours 40 minutes¶HOURS¶8¶MINUTES¶40¶SECONDS¶0 -> USER¶start a timer for 8 hours 40 minutes¶8HOURS¶8¶MINUTES¶40¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶please start a 45 minute and 15 second timer¶HOURS¶0¶MINUTES¶45¶SECONDS¶15 -> USER¶please start a 45 minute and 15 second timer¶45¶0¶15¶0\n",
      "\n",
      "Mismatch: USER¶please start a timer for 60 seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶60 -> USER¶please start a timer for 60 seconds¶6HOURS¶0¶MINUTES¶0¶SECONDS¶60\n",
      "\n",
      "Mismatch: USER¶start a timer lasting three hours and two minutes¶HOURS¶3¶MINUTES¶2¶SECONDS¶0 -> USER¶start a timer lasting three hours and two minutes¶\n",
      "\n",
      "Mismatch: USER¶start a one hour and fifteen second timer¶HOURS¶1¶MINUTES¶0¶SECONDS¶15 -> USER¶start a one hour and fifteen second timer¶1HOURS¶1¶MINUTES¶0¶SECONDS¶15\n",
      "\n",
      "Mismatch: USER¶Start a 5-minute timer for me.¶HOURS¶0¶MINUTES¶5¶SECONDS¶0 -> USER¶Start a 5-minute timer for me.¶\n",
      "\n",
      "Mismatch: USER¶Start a timer for forty four minutes and one second¶HOURS¶0¶MINUTES¶44¶SECONDS¶1 -> USER¶Start a timer for forty four minutes and one second¶44¶1¶0\n",
      "\n",
      "Mismatch: USER¶please start a seventy four minute timer¶HOURS¶0¶MINUTES¶74¶SECONDS¶0 -> USER¶please start a seventy four minute timer¶\n",
      "\n",
      "Mismatch: USER¶kick off a 2 hour 33 minute timer¶HOURS¶2¶MINUTES¶33¶SECONDS¶0 -> USER¶kick off a 2 hour 33 minute timer¶¶HOURS¶2¶MINUTES¶33¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start a 50 hour timer¶HOURS¶50¶MINUTES¶0¶SECONDS¶0 -> USER¶start a 50 hour timer¶\n",
      "\n",
      "Mismatch: USER¶I want a timer for thirty six minutes¶HOURS¶0¶MINUTES¶36¶SECONDS¶0 -> USER¶I want a timer for thirty six minutes¶¶HOURS¶0¶MINUTES¶36¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶please start a timer for 38 minutes and 44 seconds¶HOURS¶0¶MINUTES¶38¶SECONDS¶44 -> USER¶please start a timer for 38 minutes and 44 seconds¶\n",
      "\n",
      "Mismatch: USER¶i want a 15 seconds plus one and a half hour timer¶HOURS¶1¶MINUTES¶30¶SECONDS¶15 -> USER¶i want a 15 seconds plus one and a half hour timer¶¶HOURS¶1¶MINUTES¶30¶SECONDS¶15\n",
      "\n",
      "Mismatch: USER¶Start a timer for 11 minutes.¶HOURS¶0¶MINUTES¶11¶SECONDS¶0 -> USER¶Start a timer for 11 minutes.¶1HOURS¶0¶MINUTES¶11¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶please start a ten second timer¶HOURS¶0¶MINUTES¶0¶SECONDS¶10 -> USER¶please start a ten second timer¶\n",
      "\n",
      "Mismatch: USER¶Please set a timer for forty hours¶HOURS¶40¶MINUTES¶0¶SECONDS¶0 -> USER¶Please set a timer for forty hours¶\n",
      "\n",
      "Mismatch: USER¶I want a timer for seventy-seven hours¶HOURS¶77¶MINUTES¶0¶SECONDS¶0 -> USER¶I want a timer for seventy-seven hours¶¶HOURS¶77¶MINUTES¶0¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶start a timer for 40 seconds¶HOURS¶0¶MINUTES¶0¶SECONDS¶40 -> USER¶start a timer for 40 seconds¶4HOURS¶0¶MINUTES¶0¶SECONDS¶40\n",
      "\n",
      "Mismatch: USER¶start three quarters hour with 23 seconds¶HOURS¶0¶MINUTES¶45¶SECONDS¶23 -> USER¶start three quarters hour with 23 seconds¶\n",
      "\n",
      "Mismatch: USER¶Start a countdown for 11 minutes and 11 seconds.¶HOURS¶0¶MINUTES¶11¶SECONDS¶11 -> USER¶Start a countdown for 11 minutes and 11 seconds.¶\n",
      "\n",
      "Mismatch: USER¶start a timer for 9 hours and 9 minutes¶HOURS¶9¶MINUTES¶9¶SECONDS¶0 -> USER¶start a timer for 9 hours and 9 minutes¶\n",
      "\n",
      "Mismatch: USER¶I need a timer for two hours, thirty minutes and five seconds¶HOURS¶2¶MINUTES¶30¶SECONDS¶5 -> USER¶I need a timer for two hours, thirty minutes and five seconds¶¶HOURS¶2¶MINUTES¶30¶SECONDS¶5\n",
      "\n",
      "Mismatch: USER¶Can you set a timer for half a minute?¶HOURS¶0¶MINUTES¶0¶SECONDS¶30 -> USER¶Can you set a timer for half a minute?¶HOURS¶0¶MINUTES¶0¶SECONDS¶0\n",
      "\n",
      "Mismatch: USER¶Could you create a timer for sixteen minutes and nineteen seconds¶HOURS¶0¶MINUTES¶16¶SECONDS¶19 -> USER¶Could you create a timer for sixteen minutes and nineteen seconds¶\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cat eval.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4cd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llama-cpp-repo'...\n",
      "remote: Enumerating objects: 65337, done.\u001b[K\n",
      "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 65337 (delta 5), reused 5 (delta 1), pack-reused 65321 (from 2)\u001b[K\n",
      "Receiving objects: 100% (65337/65337), 181.28 MiB | 4.42 MiB/s, done.\n",
      "Resolving deltas: 100% (47527/47527), done.\n",
      "/home/dmitrievan/kaia_exps/kaia_exps/llama-cpp-repo/gguf-py\n",
      "\u001b[2mUsing Python 3.12.9 environment at: /home/dmitrievan/kaia_exps/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m4 packages\u001b[0m \u001b[2min 601ms\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 549ms\u001b[0m\u001b[0m                                              \n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0mfile:///home/dmitrievan/kaia_exps/\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mgguf\u001b[0m\u001b[2m==0.17.1 (from file:///home/dmitrievan/kaia_exps/kaia_exps/llama-cpp-repo/gguf-py)\u001b[0m\n",
      "/home/dmitrievan/kaia_exps/kaia_exps\n",
      "\u001b[2mResolved \u001b[1m276 packages\u001b[0m \u001b[2min 0.85ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m268 packages\u001b[0m \u001b[2min 0.08ms\u001b[0m\u001b[0m\n",
      "--2025-10-21 15:08:56--  https://raw.githubusercontent.com/ggml-org/llama.cpp/master/convert_lora_to_gguf.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20291 (20K) [text/plain]\n",
      "Saving to: ‘convert_lora_to_gguf.py.1’\n",
      "\n",
      "convert_lora_to_ggu 100%[===================>]  19.82K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2025-10-21 15:08:56 (6.22 MB/s) - ‘convert_lora_to_gguf.py.1’ saved [20291/20291]\n",
      "\n",
      "--2025-10-21 15:08:56--  https://raw.githubusercontent.com/ggml-org/llama.cpp/master/convert_hf_to_gguf.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 451148 (441K) [text/plain]\n",
      "Saving to: ‘convert_hf_to_gguf.py.1’\n",
      "\n",
      "convert_hf_to_gguf. 100%[===================>] 440.57K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2025-10-21 15:08:57 (4.33 MB/s) - ‘convert_hf_to_gguf.py.1’ saved [451148/451148]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/ggml-org/llama.cpp.git llama-cpp-repo\n",
    "# %cd llama-cpp-repo/gguf-py\n",
    "# !uv pip install .\n",
    "# %cd ../..\n",
    "# !uv add mistral_common\n",
    "# !wget https://raw.githubusercontent.com/ggml-org/llama.cpp/master/convert_lora_to_gguf.py\n",
    "# !wget https://raw.githubusercontent.com/ggml-org/llama.cpp/master/convert_hf_to_gguf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69139b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:lora-to-gguf:Loading base model from Hugging Face: google/gemma-3-270m-it\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:lora-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight.lora_a,      torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight.lora_b,      torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight.lora_a,      torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight.lora_b,      torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight.lora_b,        torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight.lora_a,   torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight.lora_b,   torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight.lora_b,        torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight.lora_a,      torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight.lora_b,      torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight.lora_a,      torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight.lora_b,      torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight.lora_b,        torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight.lora_a,   torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight.lora_b,   torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight.lora_b,        torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight.lora_a,     torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight.lora_b,     torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight.lora_a,     torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight.lora_b,     torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight.lora_b,       torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight.lora_a,  torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight.lora_b,  torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight.lora_b,       torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight.lora_a,     torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight.lora_b,     torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight.lora_a,     torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight.lora_b,     torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight.lora_b,       torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight.lora_a,  torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight.lora_b,  torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight.lora_b,       torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight.lora_a,     torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight.lora_b,     torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight.lora_a,     torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight.lora_b,     torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight.lora_b,       torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight.lora_a,  torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight.lora_b,  torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight.lora_b,       torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight.lora_a,     torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight.lora_b,     torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight.lora_a,     torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight.lora_b,     torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight.lora_b,       torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight.lora_a,  torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight.lora_b,  torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight.lora_b,       torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight.lora_a,     torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight.lora_b,     torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight.lora_a,     torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight.lora_b,     torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight.lora_b,       torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight.lora_a,  torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight.lora_b,  torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight.lora_b,       torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight.lora_a,     torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight.lora_b,     torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight.lora_a,     torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight.lora_b,     torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight.lora_b,       torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight.lora_a,  torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight.lora_b,  torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight.lora_b,       torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight.lora_a,     torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight.lora_b,     torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight.lora_a,     torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight.lora_b,     torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight.lora_b,       torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight.lora_a,  torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight.lora_b,  torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight.lora_b,       torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight.lora_a,     torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight.lora_b,     torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight.lora_a,     torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight.lora_b,     torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight.lora_b,       torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight.lora_a,  torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight.lora_b,  torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight.lora_b,       torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight.lora_a,       torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight.lora_b,       torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight.lora_a,      torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight.lora_b,      torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight.lora_a,      torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight.lora_b,      torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight.lora_b,        torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight.lora_a,   torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight.lora_b,   torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight.lora_b,        torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight.lora_a,      torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight.lora_b,      torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight.lora_a,      torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight.lora_b,      torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight.lora_b,        torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight.lora_a,   torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight.lora_b,   torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight.lora_b,        torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight.lora_a,      torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight.lora_b,      torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight.lora_a,      torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight.lora_b,      torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight.lora_b,        torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight.lora_a,   torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight.lora_b,   torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight.lora_b,        torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight.lora_a,      torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight.lora_b,      torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight.lora_a,      torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight.lora_b,      torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight.lora_b,        torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight.lora_a,   torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight.lora_b,   torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight.lora_b,        torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight.lora_a,      torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight.lora_b,      torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight.lora_a,      torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight.lora_b,      torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight.lora_b,        torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight.lora_a,   torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight.lora_b,   torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight.lora_b,        torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight.lora_a,      torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight.lora_b,      torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight.lora_a,      torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight.lora_b,      torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight.lora_b,        torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight.lora_a,   torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight.lora_b,   torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight.lora_b,        torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight.lora_a,      torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight.lora_b,      torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight.lora_a,      torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight.lora_b,      torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight.lora_b,        torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight.lora_a,   torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight.lora_b,   torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight.lora_b,        torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight.lora_a,      torch.float32 --> F32, shape = {2048, 16}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight.lora_b,      torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight.lora_a,      torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight.lora_b,      torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight.lora_b,        torch.float32 --> F32, shape = {16, 2048}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight.lora_a,   torch.float32 --> F32, shape = {1024, 16}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight.lora_b,   torch.float32 --> F32, shape = {16, 640}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight.lora_b,        torch.float32 --> F32, shape = {16, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight.lora_a,        torch.float32 --> F32, shape = {640, 16}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight.lora_b,        torch.float32 --> F32, shape = {16, 256}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:gemma-3-270m-lora.gguf: n_tensors = 252, total_size = 15.2M\n",
      "Writing: 100%|███████████████████████████| 15.2M/15.2M [00:00<00:00, 904Mbyte/s]\n",
      "INFO:lora-to-gguf:Model successfully exported to gemma-3-270m-lora.gguf\n"
     ]
    }
   ],
   "source": [
    "!uv run convert_lora_to_gguf.py ./qwen-timer-lora --outfile qwen-timer-lora.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a1bc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kaia env",
   "language": "python",
   "name": "kaia_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
