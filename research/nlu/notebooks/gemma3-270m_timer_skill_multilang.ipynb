{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa408c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca43cee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train lines: 2316\n",
      "Val lines: 578\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "files = {\n",
    "    \"eng\": \"chat_timer_data_eng.txt\",\n",
    "    \"rus\": \"chat_timer_data_rus.txt\",\n",
    "    \"de\": \"chat_timer_data_de.txt\",\n",
    "}\n",
    "\n",
    "train_lines = []\n",
    "val_lines = []\n",
    "\n",
    "for lang, file in files.items():\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        all_lines = [line.strip() for line in f]\n",
    "\n",
    "    unique_lines = list(set(all_lines))\n",
    "\n",
    "    if lang == \"eng\" and len(unique_lines) > 1000:\n",
    "        unique_lines = random.sample(unique_lines, 1000)\n",
    "\n",
    "    random.shuffle(unique_lines)\n",
    "\n",
    "    n_val = int(len(unique_lines) * 0.2)\n",
    "    val = unique_lines[:n_val]\n",
    "    train = unique_lines[n_val:]\n",
    "\n",
    "    train_lines.extend(train)\n",
    "    val_lines.extend(val)\n",
    "\n",
    "with open(\"train.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in train_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "with open(\"val.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in val_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"Train lines: {len(train_lines)}\")\n",
    "print(f\"Val lines: {len(val_lines)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d738a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files={\"train\": \"train.jsonl\", \"validation\": \"val.jsonl\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d1beaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'USER': 'Hey assistant, set a timer for 9 minutes.',\n",
       " 'HOURS': 0,\n",
       " 'MINUTES': 9,\n",
       " 'SECONDS': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37d7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(sample):\n",
    "    user = sample[\"USER\"]\n",
    "    hours = sample[\"HOURS\"]\n",
    "    minutes = sample[\"MINUTES\"]\n",
    "    seconds = sample[\"SECONDS\"]\n",
    "    return f\"USER:{user}\\nHOURS:{hours}\\nMINUTES:{minutes}\\nSECONDS:{seconds}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56157e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].map(lambda x: {\"text\": format_prompt(x)})\n",
    "dataset[\"validation\"] = dataset[\"validation\"].map(lambda x: {\"text\": format_prompt(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9882bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'USER': 'Hey assistant, set a timer for 9 minutes.',\n",
       " 'HOURS': 0,\n",
       " 'MINUTES': 9,\n",
       " 'SECONDS': 0,\n",
       " 'text': 'USER:Hey assistant, set a timer for 9 minutes.\\nHOURS:0\\nMINUTES:9\\nSECONDS:0'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f03c3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER:Hey assistant, set a timer for 9 minutes.\n",
      "HOURS:0\n",
      "MINUTES:9\n",
      "SECONDS:0\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a25cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"google/gemma-3-270m\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bfe932a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer(sample[\"text\"])[\"input_ids\"]) for sample in dataset[\"train\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75553b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer(sample[\"text\"])[\"input_ids\"]) for sample in dataset[\"validation\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a99a72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'left'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb3c930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sample):\n",
    "    prompt = f\"USER:{sample[\"USER\"]}\\n\"\n",
    "    prompt_len = len(tokenizer(prompt)[\"input_ids\"])\n",
    "    tokenized = tokenizer(sample[\"text\"], padding=\"max_length\", max_length=45)\n",
    "    pad_len = tokenized[\"input_ids\"].count(tokenizer.pad_token_id)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    tokenized[\"labels\"][: pad_len + prompt_len] = [-100] * (pad_len + prompt_len)\n",
    "    return tokenized\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].map(tokenize, batched=False)\n",
    "dataset[\"validation\"] = dataset[\"validation\"].map(tokenize, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65982426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['USER', 'HOURS', 'MINUTES', 'SECONDS', 'text', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93215b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 20791, 236787, 17531, 16326, 236764, 1076, 496, 20342, 573, 236743, 236819, 4310, 236761, 107, 10858, 66481, 236787, 236771, 107, 16008, 80914, 236787, 236819, 107, 149542, 236787, 236771]\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 10858, 66481, 236787, 236771, 107, 16008, 80914, 236787, 236819, 107, 149542, 236787, 236771]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0][\"attention_mask\"])\n",
    "print(dataset[\"train\"][0][\"input_ids\"])\n",
    "print(dataset[\"train\"][0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb50704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    use_cache=False,\n",
    "    attn_implementation=\"eager\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f130e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "204c40fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33mWARN\u001b[0m  Python GIL is enabled: Multi-gpu quant acceleration for MoE models is sub-optimal and multi-core accelerated cpu packing is also disabled. We recommend Python >= 3.13.3t with Pytorch > 2.8 for mult-gpu quantization and multi-cpu packing with env `PYTHON_GIL=0`.\n",
      "\u001b[33mWARN\u001b[0m  Feature `utils/Perplexity` requires python GIL or Python >= 3.13.3T (T for Threading-Free edition of Python) plus Torch 2.8. Feature is currently skipped/disabled.\n",
      "\u001b[32mINFO\u001b[0m  ENV: Auto setting PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True' for memory saving.\n",
      "\u001b[32mINFO\u001b[0m  ENV: Auto setting CUDA_DEVICE_ORDER=PCI_BUS_ID for correctness.          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:cc -pthread -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall -fPIC -fPIC -c /tmp/tmpxvw1pqg9/test.c -o /tmp/tmpxvw1pqg9/test.o\n",
      "INFO:root:cc -pthread /tmp/tmpxvw1pqg9/test.o -laio -o /tmp/tmpxvw1pqg9/a.out\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "INFO:root:cc -pthread -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall -fPIC -fPIC -c /tmp/tmp4rd8t5zd/test.c -o /tmp/tmp4rd8t5zd/test.o\n",
      "INFO:root:cc -pthread /tmp/tmp4rd8t5zd/test.o -L/usr/local/cuda-12.6 -L/usr/local/cuda-12.6/lib64 -lcufile -o /tmp/tmp4rd8t5zd/a.out\n",
      "INFO:root:cc -pthread -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -g -O3 -Wall -fPIC -fPIC -c /tmp/tmpnjdzexie/test.c -o /tmp/tmpnjdzexie/test.o\n",
      "INFO:root:cc -pthread /tmp/tmpnjdzexie/test.o -laio -o /tmp/tmpnjdzexie/a.out\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1, 'bos_token_id': 2, 'pad_token_id': 0}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='353' max='380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [353/380 08:50 < 00:40, 0.66 it/s, Epoch 18.54/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.198700</td>\n",
       "      <td>0.086829</td>\n",
       "      <td>2.116249</td>\n",
       "      <td>138780.000000</td>\n",
       "      <td>0.976405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.045152</td>\n",
       "      <td>2.028481</td>\n",
       "      <td>277560.000000</td>\n",
       "      <td>0.988949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.030087</td>\n",
       "      <td>1.563409</td>\n",
       "      <td>416340.000000</td>\n",
       "      <td>0.992267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.024895</td>\n",
       "      <td>1.215853</td>\n",
       "      <td>549900.000000</td>\n",
       "      <td>0.993987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.022359</td>\n",
       "      <td>1.216305</td>\n",
       "      <td>688680.000000</td>\n",
       "      <td>0.996189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.020613</td>\n",
       "      <td>0.906997</td>\n",
       "      <td>827460.000000</td>\n",
       "      <td>0.996070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.021335</td>\n",
       "      <td>0.827084</td>\n",
       "      <td>961020.000000</td>\n",
       "      <td>0.996066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.018274</td>\n",
       "      <td>0.811551</td>\n",
       "      <td>1099800.000000</td>\n",
       "      <td>0.996447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.019273</td>\n",
       "      <td>0.754587</td>\n",
       "      <td>1238580.000000</td>\n",
       "      <td>0.996934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.016644</td>\n",
       "      <td>0.730340</td>\n",
       "      <td>1372140.000000</td>\n",
       "      <td>0.997181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.016334</td>\n",
       "      <td>0.716352</td>\n",
       "      <td>1510920.000000</td>\n",
       "      <td>0.997676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.015885</td>\n",
       "      <td>0.708130</td>\n",
       "      <td>1649700.000000</td>\n",
       "      <td>0.997675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.016548</td>\n",
       "      <td>0.703524</td>\n",
       "      <td>1783260.000000</td>\n",
       "      <td>0.997557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>0.701761</td>\n",
       "      <td>1922040.000000</td>\n",
       "      <td>0.997550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m      1\u001b[39m training_args = TrainingArguments(\n\u001b[32m      2\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./gemma-timer-lora-multilang\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     num_train_epochs=\u001b[32m20\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     report_to=[],\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m trainer = SFTTrainer(\n\u001b[32m     20\u001b[39m     model=model,\n\u001b[32m     21\u001b[39m     train_dataset=dataset[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     args=training_args,\n\u001b[32m     25\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pln/.venv/lib/python3.12/site-packages/transformers/trainer.py:2328\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2326\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pln/.venv/lib/python3.12/site-packages/transformers/trainer.py:2672\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2665\u001b[39m context = (\n\u001b[32m   2666\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2667\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2668\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2670\u001b[39m )\n\u001b[32m   2671\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2672\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2674\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2675\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2676\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2677\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2678\u001b[39m ):\n\u001b[32m   2679\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2680\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pln/.venv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:1189\u001b[39m, in \u001b[36mSFTTrainer.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1187\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1188\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.maybe_activation_offload_context:\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pln/.venv/lib/python3.12/site-packages/transformers/trainer.py:4009\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4006\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   4008\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4009\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4011\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   4012\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4013\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4014\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   4015\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pln/.venv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:1128\u001b[39m, in \u001b[36mSFTTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   1126\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1127\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mExpected \u001b[39m\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mposition_ids\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in inputs.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m         entropy = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgather_for_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentropy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1129\u001b[39m     \u001b[38;5;28mself\u001b[39m._metrics[mode][\u001b[33m\"\u001b[39m\u001b[33mentropy\u001b[39m\u001b[33m\"\u001b[39m].append(entropy)\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1132\u001b[39m     \u001b[38;5;66;03m# When using padding-free, the attention_mask is not present in the inputs, instead we have cu_seq_lens_q,\u001b[39;00m\n\u001b[32m   1133\u001b[39m     \u001b[38;5;66;03m# cu_seq_lens_k, and max_length_k, max_length_q and position_ids.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gemma-timer-lora-multilang\",\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=64,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=25,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=25,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    peft_config=peft_config,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64bbb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./gemma-timer-lora-multilang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d7f4859",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m product\n\u001b[32m      3\u001b[39m sample_template = \u001b[33m\"\u001b[39m\u001b[33mHOURS:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMINUTES:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSECONDS:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m max_new_tokens = \u001b[38;5;28mmax\u001b[39m(\n\u001b[32m      6\u001b[39m     [\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m         \u001b[38;5;28mlen\u001b[39m(tokenizer.tokenize(sample_template.format(h, m, s)))\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m h, m, s \u001b[38;5;129;01min\u001b[39;00m product(\u001b[38;5;28mrange\u001b[39m(\u001b[32m100\u001b[39m), repeat=\u001b[32m3\u001b[39m)\n\u001b[32m      9\u001b[39m     ]\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "sample_template = \"HOURS:{}\\nMINUTES:{}\\nSECONDS:{}\"\n",
    "\n",
    "max_new_tokens = max(\n",
    "    [\n",
    "        len(tokenizer.tokenize(sample_template.format(h, m, s)))\n",
    "        for h, m, s in product(range(100), repeat=3)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3be9f7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c18c15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "840cd306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f81ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"cuda\")\n",
    "model = PeftModel.from_pretrained(base_model, \"./gemma-timer-lora-multilang\", device_map=\"cuda\")\n",
    "text_gen = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74656abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def evaluate_accuracy(\n",
    "    dataset,\n",
    "    log_file,\n",
    "    batch_size=64,\n",
    "):\n",
    "    correct = 0\n",
    "    total = len(dataset)\n",
    "\n",
    "    with open(log_file, \"w\") as file:\n",
    "        for i in tqdm(range(0, total, batch_size)):\n",
    "            texts = dataset[i : i + batch_size][\"text\"]\n",
    "            prefixes = [text.split(\"\\n\")[0] + \"\\n\" for text in texts]\n",
    "            gen_outs = text_gen(prefixes, max_new_tokens=max_new_tokens, num_beams=1, do_sample=False)\n",
    "            for text, gen_out in zip(texts, gen_outs):\n",
    "                gen_text = gen_out[0][\"generated_text\"]\n",
    "                if len(gen_text) >= len(text) and text == gen_text[: len(text)]:\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    print(f\"Mismatch: {text} -> {gen_text}\\n\", file=file)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d52a83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:21<00:00, 32.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_accuracy(dataset[\"validation\"], log_file=\"eval_multilang.log\")\n",
    "print(f\"Validation accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01e6d607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch: USER:Set a timer for three quarters of an hour.\n",
      "HOURS:0\n",
      "MINUTES:45\n",
      "SECONDS:0 -> USER:Set a timer for three quarters of an hour.\n",
      "HOURS:30\n",
      "MINUTES:15\n",
      "SECONDS:0\n",
      "\n",
      "\n",
      "Mismatch: USER:Set a timer to run for sixty eight minutes\n",
      "HOURS:0\n",
      "MINUTES:68\n",
      "SECONDS:0 -> USER:Set a timer to run for sixty eight minutes\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:68\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:start a timer for fifty seven minutes\n",
      "HOURS:0\n",
      "MINUTES:57\n",
      "SECONDS:0 -> USER:start a timer for fifty seven minutes\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:57\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:start a timer for a quarter of an hour\n",
      "HOURS:0\n",
      "MINUTES:15\n",
      "SECONDS:0 -> USER:start a timer for a quarter of an hour\n",
      "HOURS:30\n",
      "MINUTES:30\n",
      "SECONDS:0\n",
      "\n",
      "\n",
      "Mismatch: USER:create a timer lasting 20 minutes\n",
      "HOURS:0\n",
      "MINUTES:20\n",
      "SECONDS:0 -> USER:create a timer lasting 20 minutes\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:20\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:set a 7 minute and 7 second timer\n",
      "HOURS:0\n",
      "MINUTES:7\n",
      "SECONDS:7 -> USER:set a 7 minute and 7 second timer\n",
      "HOURS:7\n",
      "MINUTES:7\n",
      "SECONDS:7\n",
      "SECONDS:\n",
      "\n",
      "Mismatch: USER:start a timer running for seventy minutes\n",
      "HOURS:0\n",
      "MINUTES:70\n",
      "SECONDS:0 -> USER:start a timer running for seventy minutes\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:70\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:давай таймер на девяносто секунд\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:90 -> USER:давай таймер на девяносто секунд\n",
      "HOURS:0\n",
      "MINUTES:1\n",
      "SECONDS:30\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:засеки семнадцать минут и двадцать секунд\n",
      "HOURS:0\n",
      "MINUTES:17\n",
      "SECONDS:20 -> USER:засеки семнадцать минут и двадцать секунд\n",
      "HOURS:0\n",
      "MINUTES:15\n",
      "SECONDS:20\n",
      "\n",
      "\n",
      "Mismatch: USER:давай таймер на полтора часа\n",
      "HOURS:1\n",
      "MINUTES:30\n",
      "SECONDS:0 -> USER:давай таймер на полтора часа\n",
      "HOURS:31\n",
      "MINUTES:0\n",
      "SECONDS:0\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:таймер на семнадцать часов пять минут\n",
      "HOURS:17\n",
      "MINUTES:5\n",
      "SECONDS:0 -> USER:таймер на семнадцать часов пять минут\n",
      "HOURS:16\n",
      "MINUTES:5\n",
      "SECONDS:0\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:давай таймер на тридцать пять минут и шестнадцать секунд\n",
      "HOURS:0\n",
      "MINUTES:35\n",
      "SECONDS:16 -> USER:давай таймер на тридцать пять минут и шестнадцать секунд\n",
      "HOURS:0\n",
      "MINUTES:35\n",
      "SECONDS:17\n",
      "\n",
      "\n",
      "Mismatch: USER:таймер поставь на 16 часов 8 минут\n",
      "HOURS:16\n",
      "MINUTES:8\n",
      "SECONDS:0 -> USER:таймер поставь на 16 часов 8 минут\n",
      "HOURS:16\n",
      "MINUTES:0\n",
      "SECONDS:8\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:давай засечем 2 часа 45 минут\n",
      "HOURS:2\n",
      "MINUTES:45\n",
      "SECONDS:0 -> USER:давай засечем 2 часа 45 минут\n",
      "HOURS:2\n",
      "MINUTES:0\n",
      "SECONDS:0\n",
      "SECONDS:\n",
      "\n",
      "Mismatch: USER:включи таймер на один час тридцать одну минуту\n",
      "HOURS:1\n",
      "MINUTES:31\n",
      "SECONDS:0 -> USER:включи таймер на один час тридцать одну минуту\n",
      "HOURS:1\n",
      "MINUTES:30\n",
      "SECONDS:0\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:засеки семьдесят девять секунд\n",
      "HOURS:0\n",
      "MINUTES:1\n",
      "SECONDS:19 -> USER:засеки семьдесят девять секунд\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:79\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:поставь таймер на четверть часа и двадцать секунд\n",
      "HOURS:0\n",
      "MINUTES:15\n",
      "SECONDS:20 -> USER:поставь таймер на четверть часа и двадцать секунд\n",
      "HOURS:0\n",
      "MINUTES:30\n",
      "SECONDS:0\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:установи таймер на два часа три минуты и сорок секунд\n",
      "HOURS:2\n",
      "MINUTES:3\n",
      "SECONDS:40 -> USER:установи таймер на два часа три минуты и сорок секунд\n",
      "HOURS:2\n",
      "MINUTES:30\n",
      "SECONDS:40\n",
      "\n",
      "\n",
      "Mismatch: USER:поставь таймер на пятнадцать часов пятьдесят пять минут\n",
      "HOURS:15\n",
      "MINUTES:55\n",
      "SECONDS:0 -> USER:поставь таймер на пятнадцать часов пятьдесят пять минут\n",
      "HOURS:15\n",
      "MINUTES:0\n",
      "SECONDS:0\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:установи таймер на девять минут и четырнадцать секунд\n",
      "HOURS:0\n",
      "MINUTES:9\n",
      "SECONDS:14 -> USER:установи таймер на девять минут и четырнадцать секунд\n",
      "HOURS:0\n",
      "MINUTES:9\n",
      "SECONDS:47\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:хочу таймер на семнадцать минут\n",
      "HOURS:0\n",
      "MINUTES:17\n",
      "SECONDS:0 -> USER:хочу таймер на семнадцать минут\n",
      "HOURS:0\n",
      "MINUTES:16\n",
      "SECONDS:0\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:установи таймер на 7 часов 59 минут\n",
      "HOURS:7\n",
      "MINUTES:59\n",
      "SECONDS:0 -> USER:установи таймер на 7 часов 59 минут\n",
      "HOURS:7\n",
      "MINUTES:0\n",
      "SECONDS:0\n",
      "SECONDS:\n",
      "\n",
      "Mismatch: USER:установи таймер на девяносто девять минут\n",
      "HOURS:0\n",
      "MINUTES:99\n",
      "SECONDS:0 -> USER:установи таймер на девяносто девять минут\n",
      "HOURS:0\n",
      "MINUTES:39\n",
      "SECONDS:0\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:включи таймер на 39 часов 45 минут\n",
      "HOURS:99\n",
      "MINUTES:59\n",
      "SECONDS:0 -> USER:включи таймер на 39 часов 45 минут\n",
      "HOURS:39\n",
      "MINUTES:0\n",
      "SECONDS:0\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:таймер на полторы минуты и десять секунд\n",
      "HOURS:0\n",
      "MINUTES:1\n",
      "SECONDS:40 -> USER:таймер на полторы минуты и десять секунд\n",
      "HOURS:0\n",
      "MINUTES:1\n",
      "SECONDS:30\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:давай таймер на восемьдесят девять минут\n",
      "HOURS:0\n",
      "MINUTES:89\n",
      "SECONDS:0 -> USER:давай таймер на восемьдесят девять минут\n",
      "HOURS:0\n",
      "MINUTES:289\n",
      "SECONDS:0\n",
      "\n",
      "\n",
      "Mismatch: USER:поставь таймер на четверть часа\n",
      "HOURS:0\n",
      "MINUTES:15\n",
      "SECONDS:0 -> USER:поставь таймер на четверть часа\n",
      "HOURS:0\n",
      "MINUTES:30\n",
      "SECONDS:0\n",
      "MI\n",
      "\n",
      "Mismatch: USER:Stelle einen Timer auf 48 Stunden nicht erlaubt\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:0 -> USER:Stelle einen Timer auf 48 Stunden nicht erlaubt\n",
      "HOURS:48\n",
      "MINUTES:0\n",
      "SECONDS:0\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:setz einen Timer auf vier Stunden zehn Minuten zwanzig Sekunden\n",
      "HOURS:4\n",
      "MINUTES:10\n",
      "SECONDS:20 -> USER:setz einen Timer auf vier Stunden zehn Minuten zwanzig Sekunden\n",
      "HOURS:4\n",
      "MINUTES:0\n",
      "SECONDS:20\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:Stell einen Timer für siebzig Sekunden\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:70 -> USER:Stell einen Timer für siebzig Sekunden\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:72\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:Starte einen Timer für eine Stunde zwanzig Minuten\n",
      "HOURS:1\n",
      "MINUTES:20\n",
      "SECONDS:0 -> USER:Starte einen Timer für eine Stunde zwanzig Minuten\n",
      "HOURS:20\n",
      "MINUTES:30\n",
      "SECONDS:0\n",
      "\n",
      "\n",
      "Mismatch: USER:Leg einen Timer an für zehn Minuten\n",
      "HOURS:0\n",
      "MINUTES:10\n",
      "SECONDS:0 -> USER:Leg einen Timer an für zehn Minuten\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:0\n",
      "SECONDS:\n",
      "\n",
      "Mismatch: USER:Stell einen Timer auf null Stunden acht Minuten\n",
      "HOURS:0\n",
      "MINUTES:8\n",
      "SECONDS:0 -> USER:Stell einen Timer auf null Stunden acht Minuten\n",
      "HOURS:1\n",
      "MINUTES:8\n",
      "SECONDS:0\n",
      "SECONDS:\n",
      "\n",
      "Mismatch: USER:Timer auf eine Stunde vierundfünfzig Sekunden\n",
      "HOURS:1\n",
      "MINUTES:0\n",
      "SECONDS:54 -> USER:Timer auf eine Stunde vierundfünfzig Sekunden\n",
      "HOURS:1\n",
      "MINUTES:0\n",
      "SECONDS:59\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:könntest du einen Timer für zweiundvierzig Minuten und eine Sekunde starten\n",
      "HOURS:0\n",
      "MINUTES:42\n",
      "SECONDS:1 -> USER:könntest du einen Timer für zweiundvierzig Minuten und eine Sekunde starten\n",
      "HOURS:42\n",
      "MINUTES:42\n",
      "SECONDS:37\n",
      "\n",
      "Mismatch: USER:Timer auf fünfundachtzig Minuten setzen\n",
      "HOURS:0\n",
      "MINUTES:85\n",
      "SECONDS:0 -> USER:Timer auf fünfundachtzig Minuten setzen\n",
      "HOURS:0\n",
      "MINUTES:15\n",
      "SECONDS:0\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:Starte sofort einen Timer für fünf Stunden und sechzig Sekunden\n",
      "HOURS:5\n",
      "MINUTES:0\n",
      "SECONDS:60 -> USER:Starte sofort einen Timer für fünf Stunden und sechzig Sekunden\n",
      "HOURS:5\n",
      "MINUTES:0\n",
      "SECONDS:46\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:setz einen Timer auf einundvierzig Sekunden\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:41 -> USER:setz einen Timer auf einundvierzig Sekunden\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:47\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:setz einen Timer für siebenundachtzig Sekunden\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:87 -> USER:setz einen Timer für siebenundachtzig Sekunden\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:77\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:mach sofort einen Timer für 75 Sekunden\n",
      "HOURS:0\n",
      "MINUTES:1\n",
      "SECONDS:15 -> USER:mach sofort einen Timer für 75 Sekunden\n",
      "HOURS:0\n",
      "MINUTES:0\n",
      "SECONDS:75\n",
      "SECONDS\n",
      "\n",
      "Mismatch: USER:setz einen Timer für sechs Minuten und dreiundzwanzig Sekunden\n",
      "HOURS:0\n",
      "MINUTES:6\n",
      "SECONDS:23 -> USER:setz einen Timer für sechs Minuten und dreiundzwanzig Sekunden\n",
      "HOURS:0\n",
      "MINUTES:6\n",
      "SECONDS:39\n",
      "SECONDS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cat eval_multilang.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca457c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "pln"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
