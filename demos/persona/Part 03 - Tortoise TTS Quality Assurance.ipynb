{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19998ec2",
   "metadata": {},
   "source": [
    "It is important to establish some kind of quality assurance for the generated dubs. To do so, we will generate a large amount of dubs, and then test them against Rhasspy - we use Rhasspy anyway in our voice assistant, so it's a quick win.\n",
    "\n",
    "First, let's define a big-enough set of templates - some phrases every home assistant will have to understand eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e441473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demos.persona.intents.Intents.yes',\n",
       " 'demos.persona.intents.Intents.no',\n",
       " 'demos.persona.intents.Intents.weather',\n",
       " 'demos.persona.intents.Intents.time',\n",
       " 'demos.persona.intents.Intents.date',\n",
       " 'demos.persona.intents.Intents.transport',\n",
       " 'demos.persona.intents.Intents.timer_create',\n",
       " 'demos.persona.intents.Intents.timer_how_much_time',\n",
       " 'demos.persona.intents.Intents.timer_how_many_timers',\n",
       " 'demos.persona.intents.Intents.timer_cancel',\n",
       " 'demos.persona.intents.Intents.spotify',\n",
       " 'demos.persona.intents.Intents.cook']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from demos.persona.intents import Intents\n",
    "\n",
    "[c.name for c in Intents.get_templates()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d127861c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intent_voicing'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "batch = f'intent_voicing'\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be1cf31-e754-42a7-aad3-c44a5a0ba1fa",
   "metadata": {},
   "source": [
    "We will create dubbing for all these intents just the way we did before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fefab41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaia.persona.dub.languages.en import get_predefined_dubs, DubbingTaskCreator\n",
    "from kaia.brainbox import BrainBox\n",
    "\n",
    "ADDRESS = 'http://192.168.178.50'\n",
    "box = BrainBox()\n",
    "box_api = box.create_api(ADDRESS)\n",
    "\n",
    "def create_tasks():\n",
    "    voice = box.settings.tortoise_tts.test_voice\n",
    "    tc = DubbingTaskCreator()\n",
    "    sequences = tc.fragment(get_predefined_dubs(), Intents.get_templates(), voice)\n",
    "    optimized_sequences = tc.optimize_sequences(sequences)\n",
    "    dub_and_cut_tasks = tc.create_dub_and_cut_tasks(optimized_sequences)\n",
    "    bb_tasks = tc.create_tasks(dub_and_cut_tasks,'TortoiseTTS','aligned_dub',batch)\n",
    "    return bb_tasks\n",
    "\n",
    "\n",
    "def add_tasks(bb_tasks):\n",
    "    for task in bb_tasks:\n",
    "        box_api.add_task(task)\n",
    "\n",
    "#add_tasks(create_tasks())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e035e0e-0596-4707-92b9-001a69649053",
   "metadata": {},
   "source": [
    "And then download results and encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d68e4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaia.infra import Loc\n",
    "from ipywidgets import Audio, VBox\n",
    "from kaia.persona.dub.languages.en import DubbingPack\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "pack_path =  Path('files/intent_dubbing.zip')\n",
    "host_path =  Loc.temp_folder/'demos/dubbing/intent_dubbing'\n",
    "\n",
    "\n",
    "def download_pack(recode = False):\n",
    "    target_task = [t for t in box_api.get_tasks(batch) if t['back_track'] == 'Dubbing'][-1]\n",
    "    print(target_task['received_timestamp'])\n",
    "    result = box_api.get_result(target_task['id'])\n",
    "    if result is None:\n",
    "        raise ValueError('Not yet ready')\n",
    "    box_api.download(result, pack_path, True)\n",
    "\n",
    "#download_pack(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7e97c-9fd6-4100-949c-a83832e152e0",
   "metadata": {},
   "source": [
    "Let's check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7304f457-1931-4072-a2b8-db9da1152e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set the timer for one hour, three minutes and one second\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380be38c285e4a059acc0d87b99aeaab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Audio(value=b'RIFF\\x0c\\x14\\x03\\x00WAVEfmt \\x10\\x00\\x00\\x00\\x01\\x00\\x01\\x00\\xc0]\\x00\\x00\\x80\\xbb…"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack = DubbingPack.from_zip(host_path, pack_path)\n",
    "template = Intents.timer_create\n",
    "s = template.to_str(template.get_random_value())\n",
    "print(s)\n",
    "audios = []\n",
    "for i in range(3):\n",
    "    fname = pack.create_dubber(option_index=i).dub_string(s, template)\n",
    "    audios.append(Audio.from_file(fname, autoplay = False))\n",
    "VBox(audios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b545b6c-f88e-4ad0-9bcd-553786973aec",
   "metadata": {},
   "source": [
    "Now, let's perform testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df96577f-4b22-4aa0-b77e-c62e6c24032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaia.persona.dub.languages.en import TestingTools\n",
    "\n",
    "test = TestingTools(Intents.get_templates(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d25de669-76ec-4da1-94b6-c3de6219f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaia.persona.dub.core import RhasspyAPI\n",
    "import pandas as pd\n",
    "\n",
    "def make_test():\n",
    "    api = RhasspyAPI.create('http://127.0.0.1:12101', Intents.get_templates())\n",
    "    api.train()\n",
    "    dfs = []\n",
    "    for i in range(3):\n",
    "        df = TestingTools.samples_to_df(test.test_voice(pack.create_dubber(option_index=i), api))\n",
    "        df['option_index'] = i\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    df.to_parquet('files/test_on_intents.parquet')\n",
    "\n",
    "#make_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6567df6-c5a7-4259-9644-e063e34041ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>match_values</th>\n",
       "      <th>match_keys</th>\n",
       "      <th>match_intent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>option_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.819355</td>\n",
       "      <td>0.819355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 match  match_values  match_keys  match_intent\n",
       "option_index                                                  \n",
       "0             0.787097      0.787097         1.0           1.0\n",
       "1             0.729032      0.729032         1.0           1.0\n",
       "2             0.819355      0.819355         1.0           1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('files/test_on_intents.parquet')\n",
    "df.groupby(['option_index'])[['match','match_values','match_keys','match_intent']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed889a9-8996-414d-80eb-db205a6cd06b",
   "metadata": {},
   "source": [
    "The results are, again, decent. At least it never misses the intents, and provide completely correct interpretation in 70-80% of cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d71aea-d3bb-480f-94d6-0add0656de4e",
   "metadata": {},
   "source": [
    "The experiment also traces audiofiles that were used to compose the utterance. We can now see which fragments are particulatly problematic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21877eda-9888-4010-a6a7-92ffb2f6ae6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>option_index</th>\n",
       "      <th>text</th>\n",
       "      <th>fragment</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>minute</td>\n",
       "      <td>357181c5-2207-48da-9118-e95c564dba0f.ogg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>minute</td>\n",
       "      <td>1babebef-e216-4e42-9e3e-30523d4d814e.ogg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>zero</td>\n",
       "      <td>e9045da8-737b-46bd-9a9c-fe550485b8ed.ogg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hour</td>\n",
       "      <td>ca58adc6-1e31-4d07-ad52-4c696fcc12b6.ogg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>minute</td>\n",
       "      <td>77eeb998-27c3-403d-b8cf-c0067800d4e5.ogg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   option_index    text                                  fragment  match\n",
       "0             0  minute  357181c5-2207-48da-9118-e95c564dba0f.ogg    0.0\n",
       "1             2  minute  1babebef-e216-4e42-9e3e-30523d4d814e.ogg    0.0\n",
       "2             1    zero  e9045da8-737b-46bd-9a9c-fe550485b8ed.ogg    0.0\n",
       "3             1    hour  ca58adc6-1e31-4d07-ad52-4c696fcc12b6.ogg    0.0\n",
       "4             1  minute  77eeb998-27c3-403d-b8cf-c0067800d4e5.ogg    0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yo_fluq_ds import *\n",
    "\n",
    "fdf = Query.df(df).select_many(lambda z: ((z.match, dec) for dec in z.decomposition)).to_dataframe(columns=['match','fragment'])\n",
    "fdf = fdf.merge(pack.df.set_index('file_name'), left_on='fragment', right_index=True)\n",
    "fails = fdf.groupby(['option_index', 'text', 'fragment']).match.mean().sort_values().to_frame().reset_index()\n",
    "\n",
    "fails.loc[fails.match==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cbd2e9e-afff-420c-9a8f-a5ecf34bd2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92655c9d8404f8c842167f6f5279d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='minute/0'), Audio(value=b'OggS\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\…"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import VBox, HBox, Label\n",
    "\n",
    "def view_fails(fails):\n",
    "    return Query.df(fails).select(lambda z: HBox([Label(z.text+'/'+str(z.option_index)), Audio.from_file(host_path/z.fragment, autoplay=False)])).feed(list, VBox)\n",
    "\n",
    "view_fails(fails.loc[fails.match==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76a376a-8619-47bd-95b7-d7c665b2df90",
   "metadata": {},
   "source": [
    "Such analysis allows you to see the failures of TortoiseTTS. This way we understood and corrected:\n",
    "\n",
    "* the upper bounds of string to voice: around 60-70. Sometimes, much longer strings can be processed, but sometimes no.\n",
    "\n",
    "* that sequences like \"six, sixteenth, sixth, sixtieth, sixty, tenth\" are not the best way to organize the voiceover, as TortoiseTTS fails to pronounce \"tenth\" in this case.\n",
    "\n",
    "* How to cut sequence like \"three, four\". It appears the correct cut is \"three, \" and \"four\". \"three\"/\"four\" will lose the ending of \"three\", and \"three,\"/\" four\" will add a noise to the beginning of \"four\". Unfortunately, there is no pause tag in TortoiseTTS that could improve this even further.\n",
    "\n",
    "Moreover, you can use such an analysis to understand, which fragments need to be re-generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffedf71e-3e07-410e-8841-f6de646aca71",
   "metadata": {},
   "source": [
    "Note: to proof that these are really the faults of TortoiseTTS and not ones of Rhasspy, several times we did the following: take the sentences problematic for parsing, dub them as whole sentences via BrainBox and feed to Rhasspy again. This way, exactly 0 errors were produced. So if something fails, it is the fault of TortoiseTTS with a high probability: combinatorical issues such as wrong words/wrond limits to cut are normally checked by the unit tests, and Rhasspy is proven to be work with an adequate TortoiseTTS generated content."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
