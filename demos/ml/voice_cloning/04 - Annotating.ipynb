{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a66a56-9a3e-4266-8dec-9b4ded6a1b06",
   "metadata": {},
   "source": [
    "## Annotating\n",
    "\n",
    "For Lina, most of the TortoiseTTS voicelines are fine. However, if your samples are non-standard (e.g. low-pitch woman or high-pitched man, unsteady intotation, etc), you may get a lot of voicelines of really bad quality. This is why we do annotation, to train only on samples that are okay.\n",
    "\n",
    "Tortoise generates 3 variants of a voiceline per sentence. In my experiments, I suspected that providing training process with the multiple variants of the same text and speaker ruins process. Therefore, out of these 3 we need to choose 1. However, this is not the best idea to try to pick the best out of 3: especially for good speakers like Line, picking \"the best\" is excruciatingly hard. Hence, we assign each voicelines with tags:\n",
    "\n",
    "* Bad. Use if in doubt, you should not annotate with the mindset like \"okay, it's bad but maaaaybe\".\n",
    "* OK. Means that it's okay, the voice belongs to the character and there aren't obvious flaws (see below), __but__ it's not perfect, there is no soul inside it. That will mark the voiceline as acceptable, but will show other voicelines for this sentence.\n",
    "* Good. Means the sample is good and you don't need to hear others. Avoid the temptation to use OK too often, it's only option for bad speakers.\n",
    "\n",
    "Also you can skip sample to return to it later, or ban it: that will ban all the voicelines of this sentence for all the speakers. It should be used when a text that should be rejected in GoldenSet preparation slipped in.\n",
    "\n",
    "I have seen the following persistent problems with TortoiseTTS:\n",
    "\n",
    "* persistant noises, sometimes white noise for the half of the voiceline. If occurs too often, it might be the sign that the samples are too loud.\n",
    "* the end of the sentence is not voiced over. In particular, with words ending with -d, -t, -k, -g, etc. As a result, the model might learn these phonemes as silence and simply skip their pronounciation. So, you really need to watch out for the end of the sentence. Alternatively:\n",
    "  * You may add \"as of now\", \"as he saw\", etc. to the end of all sentences, or only to the sentences with the problematic end. These \"aw\"/\"ow\" ends are read well even at the end of the sentence.\n",
    "  * In the end, if you see that some phoneme is not voiced, simply create 10-12 voicelines for this particular phoneme. It will help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100bdd91-d82d-4935-a0ce-78abf12ff62d",
   "metadata": {},
   "source": [
    "For annotation, we have to unzip the MediaLibrary: that will unpack all the files inside it into a temp folder. We need to do it because Gradio audio control requires file.\n",
    "\n",
    "I have annotated the library to demonstrate the further process. Delete the file `files/annotation.txt` if you want to redo this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d1d503-86d6-4ed5-a41c-27572dabf1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaia.ml.voice_cloning.data_prep.annotation import AudioAnnotator\n",
    "from kaia.brainbox import BrainBox, MediaLibrary\n",
    "from kaia.infra import Loc\n",
    "from pathlib import Path\n",
    "import gradio as gr\n",
    "\n",
    "lib = MediaLibrary.read(Path('files/voicelines.zip')).unzip(Loc.temp_folder/'audio_annotator_temp_files')\n",
    "\n",
    "annotator = AudioAnnotator(lib, Path('files/annotation.txt'), None)\n",
    "\n",
    "with gr.Blocks() as annotation_interface:\n",
    "    annotator.generate_interface()\n",
    "\n",
    "annotation_interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
